library(ISLR)
library(tidyverse)
library(dplyr)
library(MASS)
library(lattice)
library(caret)
library(tree)
library(randomForest)
library(e1071)
library(kernlab)
data(Auto)
Auto$origin = as.factor(Auto$origin)
options(width = 110)
Auto$origin2 <- ifelse(Auto$origin == 1, 1, 0)
set.seed(123)
# Approximately 80% of the data should be in the training set.
train_indices <- createDataPartition(Auto$origin, p = 0.8, list = FALSE)
# Create training and test sets
train_set <- Auto[train_indices, ]  # 315
test_set <- Auto[-train_indices, ]  # 77 rows
# Fit the classification tree model
tree_model <- tree(origin2 ~ mpg + cylinders + displacement + horsepower + weight + acceleration + year, data = train_set)
summary(tree_model)
# Predict origin2 before pruning
predicted_before_pruning <- predict( tree_model, newdata = test_set )
# Convert predicted probabilities to class labels (0 or 1) using a threshold of 0.5
predicted_before_pruning <- ifelse(predicted_before_pruning >= 0.5, 1, 0)
# get test error
#cat("Error before pruning: ", mean(predicted_before_pruning != test_set$origin2))
# Prune the tree using cross-validation
cv_pruned_tree <- cv.tree(tree_model)
# Plot the pruned tree
pruned_tree <- prune.tree(tree_model, best = cv_pruned_tree$size[which.min(cv_pruned_tree$dev)])
plot(pruned_tree)
text(pruned_tree)
# Predict origin2 using the pruned tree model
predicted_origin2 <- predict(pruned_tree, newdata = test_set)
# Convert predicted probabilities to class labels (0 or 1) using a threshold of 0.5
predicted_origin2 <- ifelse(predicted_origin2 >= 0.5, 1, 0)
# Calculate test error
test_error <- mean(predicted_origin2 != test_set$origin2)
# Print test error
print(test_error)
rf.auto = randomForest(origin2~.-name -origin, data=train_set)
rf.auto
#evaluate on train set
rf.train.predicted <-predict( rf.auto, newdata=train_set )
rf.train.predicted <- ifelse(rf.train.predicted >= 0.5, 1, 0)
cat("Train Error: ", mean( rf.train.predicted != train_set$origin2) )
# train on test set and evaluate performance
rf.predicted <- predict( rf.auto, newdata = test_set )
# Convert predicted probabilities to class labels (0 or 1) using a threshold of 0.5
rf.predicted_class <- ifelse(rf.predicted >= 0.5, 1, 0)
rf.test_error <- mean( rf.predicted_class != test_set$origin2)
cat("Test Error: ", rf.test_error)
#set.seed(1011)
#sv.Auto <- Auto[, -c("name", "origin")]
svc_model <- svm(origin2 ~ . - name - origin, data = Auto, kernel = "linear", scale = FALSE, max_iter = 20000)
tune.out <- tune( svm, origin2 ~. -name -origin, data = Auto,
kernel = "linear",
ranges = list(  cost = c(0.1, 1, 10, 20)
, gamma = c(0.1, 0.5, 1)
),
tunecontrol = tune.control(sampling = "cross", cross = 5)
)
summary(tune.out)
svm_model <- svm(origin2 ~ . -name -origin, data = Auto, kernel = "radial", scale = FALSE)
tune.svm <- tune( svm, origin2 ~. -name -origin, data = Auto,
kernel = "radial",
ranges = list(  cost = c(1, 10, 25, 50, 75)
, gamma = c(0.1, 0.5, 1)
),
tunecontrol = tune.control(sampling = "cross", cross = 5)
)
summary(tune.svm)
# Select two features for visualization (e.g., mpg and weight)
#features <- c("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "year")
# Extract the selected features and the target variable from the dataset
# X <- Auto[, features]
# y <- Auto$origin2
# Predict class labels for each point in the grid using the SVC model
svc_predictions <- predict(svc_model, newdata = test_set)
plot(svc_predictions, col = ifelse(svc_predictions >= 0, "red", "blue"), pch = 16, xlab = "Observation Number", ylab = "Predicted Value")
legend("topright", legend = c("American", "Non-American"), fill = c("red", "blue"))
svm_predictions <- predict(svm_model, newdata= test_set)
plot(svm_predictions, col = ifelse(svm_predictions >= 0, "red", "blue"), pch = 16, xlab = "Observation Number", ylab = "Predicted Value")
legend("topright", legend = c("American", "Non-American"), fill = c("red", "blue"))
# Load required libraries
library(cluster)
library(ggplot2)
library(ggdendro)
library(caret)
# Load Auto data
#data(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin", "origin2"))]
# Perform hierarchical clustering
distances <- dist(Auto, method = "euclidean")
hclust_model <- hclust(distances, method = "complete")
# Visualize dendrogram
dendro <- as.dendrogram(hclust_model)
ggdendrogram(dendro) +
labs(title = "Dendrogram of Hierarchical Clustering",
x = "Cars",
y = "Distance") +
theme(axis.text.x = element_blank())
# Cut dendrogram at a height resulting in three distinct clusters
cluster_labels <- cutree(hclust_model, k = 3)
# Compare clustering solution to 'origin' variable
confusion_matrix <- table(cluster_labels, Auto$origin)
length(cluster_labels)
length(Auto$origin)
# Load Auto data
data(Auto)
length(Auto$origin)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin", "origin2"))]
length(Auto$origin)
# Load Auto data
data(Auto)
str(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin"))]
str(Auto)
# Load required libraries
library(cluster)
library(ggplot2)
library(ggdendro)
library(caret)
# Load Auto data
data(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin"))]
# Load Auto data
data(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin"))]
# Perform hierarchical clustering
distances <- dist(Auto, method = "euclidean")
hclust_model <- hclust(distances, method = "complete")
# Visualize dendrogram
dendro <- as.dendrogram(hclust_model)
ggdendrogram(dendro) +
labs(title = "Dendrogram of Hierarchical Clustering",
x = "Cars",
y = "Distance") +
theme(axis.text.x = element_blank())
# Cut dendrogram at a height resulting in three distinct clusters
cluster_labels <- cutree(hclust_model, k = 3)
# Compare clustering solution to 'origin' variable
confusion_matrix <- table(cluster_labels, Auto$origin)
# Load required libraries
library(cluster)
library(ggplot2)
library(ggdendro)
library(caret)
# Load Auto data
data(Auto)
# Remove 'origin' feature
origin_values = Auto$origin
Auto <- Auto[, !(names(Auto) %in% c("origin"))]
# Perform hierarchical clustering
distances <- dist(Auto, method = "euclidean")
hclust_model <- hclust(distances, method = "complete")
# Visualize dendrogram
dendro <- as.dendrogram(hclust_model)
ggdendrogram(dendro) +
labs(title = "Dendrogram of Hierarchical Clustering",
x = "Cars",
y = "Distance") +
theme(axis.text.x = element_blank())
# Cut dendrogram at a height resulting in three distinct clusters
cluster_labels <- cutree(hclust_model, k = 3)
# Compare clustering solution to 'origin' variable
confusion_matrix <- table(cluster_labels, origin_values)
confusion_matrix
# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
# Perform k-means clustering with k = 3
kmeans_result <- kmeans(scale(Auto), centers = 3, nstart = 20)
# Load the Auto dataset
data(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin", "names"))]
# Perform k-means clustering with k = 3
kmeans_result <- kmeans(scale(Auto), centers = 3, nstart = 20)
Auto
# Load the Auto dataset
data(Auto)
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin", "name"))]
Auto
Auto
# Remove 'origin' and 'origin2' variables
Auto <- Auto[, !(names(Auto) %in% c("origin", "name"))]
# Perform k-means clustering with k = 3
kmeans_result <- kmeans(scale(Auto), centers = 3, nstart = 20)
# Get cluster labels
cluster_labels <- kmeans_result$cluster
# Compare clustering solution to 'origin' variable
confusion_matrix <- table(cluster_labels, origin_values)
# Print confusion matrix
print(confusion_matrix)
Auto
# Perform PCA
pca_result <- prcomp(Auto, scale. = TRUE)
# Print summary
summary(pca_result)
# Load required libraries
library(caret)
library(pls)
# Load the data
data(Auto)
# Standardize predictor variables (excluding mpg)
X <- scale(Auto[, -which(names(Auto) %in% c("mpg"))])
# Load the data
data(Auto)
Auto <- Auto[, !(names(Auto) %in% c("name"))]
# Standardize predictor variables (excluding mpg)
X <- scale(Auto[, -which(names(Auto) %in% c("mpg"))])
# Perform PCA
pca_model <- prcomp(X, scale. = TRUE)
# Select number of components
# For simplicity, let's retain all components
num_components <- ncol(X)
# Transform predictors into principal components
X_pc <- predict(pca_model, newdata = X)[, 1:num_components]
# Fit PCR model
pcr_model <- lm(mpg ~ ., data = data.frame(X_pc, mpg = Auto$mpg))
# Print summary of PCR model
summary(pcr_model)
setwd("~/Desktop/DSP 569/Assignment 5")
setwd("~/Desktop/DSP 569/Assignment 6")
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
glimpse(possum.dat)
Glimpse(possum.dat)
## You will need a series of packages, you can put them below.
## Exactly which packages you need will depend on how you run the analysis (follow what was in the lecture or do another way, as long as it answers the question correctly, its fine).
library(dplyr)
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
Glimpse(possum.dat)
glimpse(possum.dat)
possum.dat <- possum.dat %>%
select(-case, -site, -pop, -sex)
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex)
possum.dat <- possum.dat %>% select(-case, -site, -Pop, -sex)
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
possum.dat <- possum.dat %>% select(-case, -site, -Pop, -sex)
head(possum.dat)
## Rescale the data for use in the ANN
normalize <- function(x) { return ( (x-min(x))/(max(x)-min(x))) }
possum_n <- lapply( possum.dat, normalize )
glimpse(possum_n)
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
colnames(possum.dat)
## We want to work with just the numeric data so get rid of the columns case, site, pop, and sex, and remove rows with NAs
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex) %>%
drop_na()
## We want to work with just the numeric data so get rid of the columns case, site, pop, and sex, and remove rows with NAs
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex) %>%
drop_na()
library(tidyr)
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
## We want to work with just the numeric data so get rid of the columns case, site, pop, and sex, and remove rows with NAs
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex) %>%
drop_na()
colnames(possum.dat)
str(possum.dat)
possum_n <- as.data.frame( lapply(possum.dat, normalize) )
possum_n <- as.data.frame( lapply(possum.dat, normalize) )       # lapply() returns a list therefore we convert it to a data frame
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
## We want to work with just the numeric data so get rid of the columns case, site, pop, and sex, and remove rows with NAs
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex) %>%
drop_na()
## Rescale the data for use in the ANN
normalize <- function(x) { return ( (x-min(x))/(max(x)-min(x))) }
possum_n <- as.data.frame( lapply(possum.dat, normalize) )       # lapply() returns a list therefore we convert it to a data frame
glimpse(possum_n)
## Split into training and testing data, make it an 80/20 split. Reminder, if you are randomizing anything in the following steps, please set a seed so I can reproduce your answer.
set.seed(60)
library(caret)
colnames(possum_n)
## Split into training and testing data, make it an 80/20 split. Reminder, if you are randomizing anything in the following steps, please set a seed so I can reproduce your answer.
set.seed(60)
in_train <- createDataPartition(possum_n$age, p=0.80, list=FALSE)
train_data <- possum_n[in_train]
test_data <- possum_n[-in_train]
## Split into training and testing data, make it an 80/20 split. Reminder, if you are randomizing anything in the following steps, please set a seed so I can reproduce your answer.
set.seed(60)
in_train <- createDataPartition(possum_n$age, p=0.80, list=FALSE)
train_data <- possum_n[in_train, ]
test_data <- possum_n[-in_train, ]
summary(possum_n$age)
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly, data=train_data)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data,
hidden=1)
## Create a Visualization of the network
plot(possom_model)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data,
hidden=0)
## Create a Visualization of the network
plot(possom_model)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data,
hidden=0)
## Create a Visualization of the network
plot(possom_model)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data)
## Create a Visualization of the network
plot(possom_model)
## Create a Visualization of the network
plot(possom_model)
## Create a Visualization of the network
plot(possom_model)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data)
predicted_strength <- model_results$net.result
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data)
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=5)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=2)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=3)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=1)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=10)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden=4)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Read in the data set and summarize the data.
possum.dat <- read.csv("possum.csv", header = T)
## We want to work with just the numeric data so get rid of the columns case, site, pop, and sex, and remove rows with NAs
possum.dat <- possum.dat %>%
select(-case, -site, -Pop, -sex) %>%
drop_na()
## Re-scale the data for use in the ANN
normalize <- function(x) { return ( (x-min(x))/(max(x)-min(x))) }
possum_n <- as.data.frame( lapply(possum.dat, normalize) )       # lapply() returns a list therefore we convert it to a data frame
## Split into training and testing data, make it an 80/20 split. Reminder, if you are randomizing anything in the following steps, please set a seed so I can reproduce your answer.
set.seed(60)
in_train <- createDataPartition(possum_n$age, p=0.80, list=FALSE)
train_data <- possum_n[in_train, ]
test_data <- possum_n[-in_train, ]
## Train a simple multilayer feedforward network with the default settings using only a single hidden node.
# The neuralnet function will automatically exclude age from the predictors when using the formula age ~ ...
possom_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data)
## Create a Visualization of the network
plot(possom_model)
## Evaluate your model by looking at the correlation between the predicted (or computed) ages versus the ages in the test dataset.
model_results <- compute(possom_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Create a Visualization of the network
plot(possom_model)
## Try improving your ANN by adding two hidden layers of 6, and also change the activation function to a softplus activation function
softplus <- function(x) {log(1+exp(x))}
possom_improved_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
possom_improved_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden = c(6,6), act.fct = softplus)
## Create a Visualization of the network
plot(possom_model)
## Create a Visualization of this new network
plot(possom_improved_model)
possom_improved_model <- neuralnet(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data=train_data, hidden = c(6,6), act.fct = softplus)
## Create a Visualization of this new network
plot(possom_improved_model)
model_results <- compute(possom_improved_model, test_data[, -which(names(test_data) == "age")])
predicted_strength <- model_results$net.result
cor(predicted_strength, test_data$age)
## Create a Visualization of this new network
plot(possom_improved_model)
possom_lm <- glm(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
family=binomial,
data = train_data)
possom_lm <- glm(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
family=gaussian(),
data = train_data)
summary(possom_lm)
model_results <- predict(possom_lm, test_data[, -which(names(test_data) == "age")])
# Train a logistic regression model with the selected principal components
log_reg_pca_model <- glm(age ~ PC1 + PC2 + PC3 + PC4 + PC5, data = pca_data, family = gaussian())
# Fit a linear model for predicting age
log_reg_model <- glm(age ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly,
data = train_data,
family = gaussian())  # gaussian family for continuous response variable
# View the summary of the model
summary(log_reg_model)
# Predict on test data
predicted_age_log_reg <- predict(log_reg_model, test_data)
# Calculate SSE for test set
sse_log_reg <- sum((predicted_age_log_reg - test_data$age)^2)
sse_log_reg
# Calculate the correlation between the predicted age and actual age
cor_log_reg <- cor(predicted_age_log_reg, test_data$age)
cor_log_reg
log_reg_model <- glm(age ~ belly,
data = train_data,
family = gaussian())  # gaussian family for continuous response variable
# View the summary of the model
summary(log_reg_model)
# Predict on test data
predicted_age_log_reg <- predict(log_reg_model, test_data)
# Calculate SSE for test set
sse_log_reg <- sum((predicted_age_log_reg - test_data$age)^2)
sse_log_reg
# Predict age using the logistic regression model
predicted_age_log_reg <- predict(log_reg_model, newdata = test_data)
# Calculate the correlation between the predicted age and actual age
cor_log_reg <- cor(predicted_age_log_reg, test_data$age)
cor_log_reg
# Load necessary package
library(FNN)
# Assuming possum_n is your data with the 'age' column as the target
train_data <- possum_n[train_index, ]  # Training set (use the same split as your previous models)
# Perform KNN regression (use features excluding 'age')
knn_reg_model <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$age, k = 5)
install.packages("FNN")
# Load necessary package
library(FNN)
# Perform KNN regression (use features excluding 'age')
knn_reg_model <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$age, k = 5)
# Predicted ages from the KNN regression model
predicted_age_knn <- knn_reg_model$pred
# Calculate the correlation between predicted and actual values
cor_knn <- cor(predicted_age_knn, test_data$age)
cor_knn
# Perform KNN regression (use features excluding 'age')
knn_reg_model <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$age, k = 10)
# Predicted ages from the KNN regression model
predicted_age_knn <- knn_reg_model$pred
# Calculate the correlation between predicted and actual values
cor_knn <- cor(predicted_age_knn, test_data$age)
cor_knn
# Perform KNN regression (use features excluding 'age')
knn_reg_model <- knn.reg(train = train_data[, -1], test = test_data[, -1], y = train_data$age, k = 12)
# Predicted ages from the KNN regression model
predicted_age_knn <- knn_reg_model$pred
# Calculate the correlation between predicted and actual values
cor_knn <- cor(predicted_age_knn, test_data$age)
cor_knn
setwd("~/Desktop/DSP 569/Assignment 6")
